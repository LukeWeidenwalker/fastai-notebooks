{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_pets.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN6x2hYmMZOXFWQ9e3SOgcU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LukeWeidenwalker/fastai-notebooks/blob/master/05_pets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YA7CQrMidj2",
        "outputId": "9368830c-e4d0-4a85-9fd0-07a8f7d1f014"
      },
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook \n",
        "fastbook.setup_book()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRylI0tglMMu"
      },
      "source": [
        "from fastbook import *\n",
        "from fastai.vision.all import *"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "1_Q38o2VlUgU",
        "outputId": "d24ba5b3-d01b-48e0-cb55-71041b257096"
      },
      "source": [
        "path = untar_data(URLs.PETS)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIJaobNUlbzh"
      },
      "source": [
        "pets = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
        "                 get_items=get_image_files,\n",
        "                 splitter=RandomSplitter(seed=42),\n",
        "                 get_y=using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'),\n",
        "                 item_tfms=Resize(460),\n",
        "                 batch_tfms=aug_transforms(size=224, min_scale=0.75))\n",
        "dls = pets.dataloaders(path/\"images\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjUfBvH1ofy4",
        "outputId": "4d07f408-4ed0-46d8-fde0-0733bc2e6c5b"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /root/.fastai/data/oxford-iiit-pet/images\n",
            "Found 7390 items\n",
            "2 datasets of sizes 5912,1478\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: partial -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /root/.fastai/data/oxford-iiit-pet/images/basset_hound_51.jpg\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=333x500\n",
            "  Pipeline: partial -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /root/.fastai/data/oxford-iiit-pet/images/basset_hound_51.jpg\n",
            "    applying partial gives\n",
            "      basset_hound\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(14)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=333x500, TensorCategory(14))\n",
            "\n",
            "\n",
            "Collecting items from /root/.fastai/data/oxford-iiit-pet/images\n",
            "Found 7390 items\n",
            "2 datasets of sizes 5912,1478\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: partial -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (460, 460), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Flip -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 0.5} -> RandomResizedCropGPU -- {'size': (224, 224), 'min_scale': 0.75, 'ratio': (1, 1), 'mode': 'bilinear', 'valid_scale': 1.0, 'p': 1.0} -> Brightness -- {'max_lighting': 0.2, 'p': 1.0, 'draw': None, 'batch': False}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (460, 460), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=333x500, TensorCategory(14))\n",
            "    applying Resize -- {'size': (460, 460), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=460x460, TensorCategory(14))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x460x460, TensorCategory(14))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Flip -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 0.5} -> RandomResizedCropGPU -- {'size': (224, 224), 'min_scale': 0.75, 'ratio': (1, 1), 'mode': 'bilinear', 'valid_scale': 1.0, 'p': 1.0} -> Brightness -- {'max_lighting': 0.2, 'p': 1.0, 'draw': None, 'batch': False}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x460x460, TensorCategory([14,  1,  6, 34], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x460x460, TensorCategory([14,  1,  6, 34], device='cuda:0'))\n",
            "    applying Flip -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 0.5} gives\n",
            "      (TensorImage of size 4x3x460x460, TensorCategory([14,  1,  6, 34], device='cuda:0'))\n",
            "    applying RandomResizedCropGPU -- {'size': (224, 224), 'min_scale': 0.75, 'ratio': (1, 1), 'mode': 'bilinear', 'valid_scale': 1.0, 'p': 1.0} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([14,  1,  6, 34], device='cuda:0'))\n",
            "    applying Brightness -- {'max_lighting': 0.2, 'p': 1.0, 'draw': None, 'batch': False} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([14,  1,  6, 34], device='cuda:0'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4X1pdXFoo7c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}